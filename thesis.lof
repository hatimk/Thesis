\select@language {english}
\addvspace {10\p@ }
\contentsline {xchapter}{State of the art}{13}{chapter.8}
\contentsline {figure}{\numberline {1.1}{\ignorespaces The dialogue chain\relax }}{20}{figure.caption.19}
\contentsline {figure}{\numberline {1.2}{\ignorespaces A 5-Best example corresponding to the sentence "I would like to book a flight from New-York to Los Angeles".\relax }}{21}{figure.caption.26}
\contentsline {figure}{\numberline {1.3}{\ignorespaces The interaction cycle between the agent and the environment in reinforcement learning\relax }}{31}{figure.caption.49}
\contentsline {xpart}{State of the art}{13}{part.7}
\addvspace {10\p@ }
\contentsline {xchapter}{Turn-taking phenomena taxonomy}{43}{chapter.76}
\contentsline {xpart}{Contributions}{43}{part.75}
\addvspace {10\p@ }
\contentsline {xchapter}{Turn-taking decision module: the Scheduler}{57}{chapter.120}
\contentsline {figure}{\numberline {3.1}{\ignorespaces The Scheduler: an interface between the client and the service\relax }}{58}{figure.caption.123}
\contentsline {figure}{\numberline {3.2}{\ignorespaces Time sharing in traditional and incremental settings\relax }}{59}{figure.caption.125}
\contentsline {figure}{\numberline {3.3}{\ignorespaces Incremental behaviour with the Scheduler\relax }}{60}{figure.caption.128}
\contentsline {figure}{\numberline {3.4}{\ignorespaces A double context: the real context and the simulation context.\relax }}{61}{figure.caption.129}
\contentsline {figure}{\numberline {3.5}{\ignorespaces The incremental version of the CFAsT project. The traditional view is represented on the left and the new incremental one is depicted on the left.\relax }}{62}{figure.caption.132}
\addvspace {10\p@ }
\contentsline {xchapter}{Dialogue strategies}{69}{chapter.138}
\contentsline {figure}{\numberline {4.1}{\ignorespaces Slot-filling strategies efficiency comparison ($n_s = 5$)\relax }}{75}{figure.caption.158}
\addvspace {10\p@ }
\contentsline {xchapter}{Incremental dialogue simulation}{79}{chapter.166}
\contentsline {figure}{\numberline {5.1}{\ignorespaces Simulated environment architecture\relax }}{80}{figure.caption.168}
\contentsline {figure}{\numberline {5.2}{\ignorespaces ASR score sampling distribution ($\sigma _{conf} = 1$)\relax }}{83}{figure.caption.182}
\contentsline {figure}{\numberline {5.3}{\ignorespaces An illustration of the incremental ASR output N-Best update (BF=0.2)\relax }}{85}{figure.caption.189}
\addvspace {10\p@ }
\contentsline {xchapter}{Handcrafted strategies for improving dialogue efficiency}{91}{chapter.209}
\contentsline {figure}{\numberline {6.1}{\ignorespaces Simulated mean duration (left) and dialogue task completion (right) for different noise levels\relax }}{96}{figure.caption.215}
\contentsline {figure}{\numberline {6.2}{\ignorespaces Mean dialogue duration and task completion for aggregated strategies.\relax }}{97}{figure.caption.219}
\contentsline {figure}{\numberline {6.3}{\ignorespaces Mean dialogue duration and task completion for different turn-taking phenomena.\relax }}{98}{figure.caption.220}
\contentsline {figure}{\numberline {6.4}{\ignorespaces INCOHERENCE\_INTERP evaluated in a more adapted task\relax }}{99}{figure.caption.229}
\addvspace {10\p@ }
\contentsline {xchapter}{Reinforcement learning for turn-taking optimisation}{101}{chapter.231}
\contentsline {figure}{\numberline {7.1}{\ignorespaces Learning curve (0-500: pure exploration, 500-2500: exploration/exploitation, 2500-3000: pure exploitation)\relax }}{107}{figure.caption.252}
\contentsline {figure}{\numberline {7.2}{\ignorespaces Mean dialogue duration and task for the non-incremental, the baseline incremental and the RL incremental strategies under different noise conditions.\relax }}{108}{figure.caption.253}
\addvspace {10\p@ }
\contentsline {xchapter}{Experiment with real users}{109}{chapter.255}
\addvspace {10\p@ }
\contentsline {xchapter}{A new reinforcement learning approach adapted to incremental dialogue}{111}{chapter.258}
