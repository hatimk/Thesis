\chapter{Incremental dialogue simulation}
\label{ch:simulation}

\section{Agenda management task}

	A personal agenda assistant has been implemented as our task for the experiments. The user can add, move or delete events in his agenda. For instance, a request could be: \textit{I would like to add the event football game on March $3^{rd}$ from 9 to 10 pm}\footnote{The dialogues are actually in french but they are translated in English in this thesis}. This is a slot filling task with four slots:
    
    \begin{itemize}
    	\item \textbf{ACTION:} The type of action the user wants to perform. Can take three different values: ADD, MODIFY or DELETE.
        \item \textbf{DESCRIPTION:} The title of the event.
        \item \textbf{DATE:} The date of the event.
        \item \textbf{SLOT:} The time slot of the event.
    \end{itemize}
    
    However, the no overlap is tolerated between events in the agenda.
    
    The US is given two lists of events: \textit{InitList} and \textit{ToAddList}. The first one contains the events that already exist in the dialogue before the dialogue and the second one contains the ones that the US is supposed to add during the dialogue. Each event is associated with a priority value and the US must prefer adding the ones with high probability first. Its aim is to make as many events as possible fit in the agenda.
		
		\section{The service}
		
			\subsection{Natural Language Understanding}
			
				A recursive algorithm transforms the user's utterance hypothesis into a concept tree. To do that, a set of rules have been defined. Each rule transforms a word, a concept or any combination of the two into a new concept. Three types of rules are used; they are depicted in table \ref{tab:ruletypes}
				
				\begin{table}[t]
					\fontsize{8}{10}\selectfont
					\caption{\label{tab:ruletypes} {NLU rules types}}
					\vspace{2mm}
					\centerline{
						\begin{tabular}{|l|l|l|}
							\hline
							\textbf{Rule type} & \textbf{Description} & \textbf{Example} \\
							\hline
							Tag & Words are associated to a label & remove : [DELETE] \\
							Regular expressions & Spots words that satisfy a regular expression & Regex([0-9]+) : NUMBER(\$word) \\
							Combine & Words and concepts are mapped into a new concept & Combine(NUMBER,MONTH) : DATE \\
							\hline
						\end{tabular}
					}
				\end{table}
				
				The NLU algorithm keeps applying these rules the order they appear in the rules file until two consecutive results are identical. For instance, parsing the sentence \textit{I want to add the event birthday party on January $6^{th}$ from 9pm to 11pm} is performed following these steps:
                
                \begin{enumerate}
            	\item \textbf{I want to ADD the TAG\_EVENT birthday party on MONTH(January) NUMBER(6) from TIME(9,0) to TIME(11,0)}
                	\begin{itemize}
                    	\item add : [ADD]
                        \item event : [TAG\_EVENT]
                        \item Regex(janvier|...|decembre) : MONTH(\$word)
                        \item Regex([0-9]+) : NUMBER(\$word)
                        \item Regex((([0-1]?[0-9])|(2[0-3]))h([0-5][0-9])?) : TIME(\$word)
                    \end{itemize}
              	\item \textbf{I want to ADD the TAG\_EVENT birthday party on DATE(6,1) \\ SLOT(TIME(21,0),TIME(23,0))}
                	\begin{itemize}
                    	\item Combine(NUMBER,MONTH) : DATE(NUMBER,MONTH)
                        \item Combine(from,TIME\_1,to,TIME\_2) : SLOT(TIME\_1,TIME\_2)
                    \end{itemize}
              	\item \textbf{I want to ADD EVENT(birthday party, DATE(6,1), \\ SLOT(TIME(21,0),TIME(23,0)))}
                	\begin{itemize}
                    	\item Combine(TAG\_EVENT,\$x,on,DATE,SLOT) : EVENT(\$x,DATE,SLOT)
                    \end{itemize}
               	\item \textbf{I want ACTION(ADD, EVENT(birthday party, DATE(6,1), \\ SLOT(TIME(21,0),TIME(23,0))))}
                	\begin{itemize}
                    	\item Combine(ADD,EVENT) : ACTION(ADD,EVENT)
                    \end{itemize}
            \end{enumerate}
                
                
%                 \begin{sidewaystable}
%     				\centering
%                     \fontsize{8}{10}\selectfont
% 					\caption{\label{tab:parsingex} {Parsing example}}
%                     \begin{tabular}{|l|l|l|}
% 							\hline
% 							\textbf{Step} & \textbf{Parsing result} & \textbf{Rules applied} \\
% 							\hline
% 							0 & I want to add the event birthday party on January $6^{th}$ from 9pm to 11pm & \\
% 							1 & I want to ADD the TAG\_EVENT birthday party on MONTH(January) NUMBER(6) & \\
%                             & from TIME(9,0) to TIME(11,0) & add : [ADD] \\
% 							& & event : [TAG\_EVENT] \\
% 							& & Regex(january|...|february) : MONTH(\$word) \\
% 							& & Regex([0-9]+) : NUMBER(\$word) \\
% 							& & Regex((([0-1]?[0-9])|(2[0-3]))h([0-5][0-9])?) : TIME(\$word) \\
% 							2 & I want to ADD the TAG\_EVENT birthday party on DATE(6,1) SLOT(TIME(21,0),TIME(23,0)) & Combine(NUMBER,MONTH) : DATE(NUMBER,MONTH) \\
% 							& & Combine(from,TIME\_1,to,TIME\_2) : SLOT(TIME\_1,TIME\_2) \\
% 							3 & I want to ADD EVENT(birthday party, DATE(6,1), SLOT(TIME(21,0),TIME(23,0))) & Combine(TAG\_EVENT,\$x,on,DATE,SLOT) : EVENT(\$x,DATE,SLOT) \\
% 							4 & I want ACTION(ADD, EVENT(birthday party, DATE(6,1), SLOT(TIME(21,0),TIME(23,0)))) & Combine(ADD,EVENT) : ACTION(ADD,EVENT) \\
% 							\hline
% 						\end{tabular}
%     			\end{sidewaystable}
    
\section{User simulator}
	\subsection{Overview}
    
    	The User Simulator (US) is composed of six modules (see Figure \ref{fig:archi}). The Intent Manager, the NLU, the Verbosity Manager, the ASR output simulator, the NLG and the Patience Manager. In every incremental dialogue setup, each dialogue turn is divided into smaller micro-turn given a particular criteria; a micro-turn could be a time window (500 milliseconds for example), it could also be word-based or concept-based (a new word or a new concept marks the end of a micro-turn). The US described here is word-based.
        
        %HK> Blinder un peu, c'est une simplification du barge-in human car rien ne garantit que la personne interrompue se taise.
        At each micro-turn, the US generates a partial N-Best. It embeds the whole utterance from the beginning of the turn (\textit{restart incremental} mode \cite{Schlangen2011}). On the other hand, either the US receives an answer from the Scheduler at a certain micro-turn and it stops speaking, either it does not and it continues speaking if it has additional thing to say, or spontaneously releases the floor. When the dialogue lasts for too long without achieving the task at hand, the US can end the dialogue.
        
        In the following, the different components of the US are described in detail.
        
        \begin{figure*}[htb]
          \centering
          \includegraphics[scale=0.5]{figures/ArchiSimuSys.pdf}
          \caption{Simulated environment architecture}
          \label{fig:archi}
        \end{figure*}
    
    \subsection{Intent Manager}
    \label{subsec:intentmanager}
    
    	The aim of the US is to make the biggest number possible of events taken from \textit{InitList} and \textit{ToAddList} fit in the agenda. The events with the highest priority are considered first. To do so, the Intent Manager runs Algorithm \ref{algo:intent} where
        
        %HK> Cf les remarques de Romain sur le premier draft IWSDS pour cette partie.
        
        \begin{itemize}
          \item \textbf{actionList:} the list of actions to be performed by the system (initially the list of ADD actions corresponding to \textit{ToAddList}).
          \item \textbf{act():} function that performs a list of actions.
          \item \textbf{perform():} function that performs a single action.
          \item \textbf{alternatives():} function that returns the alternative events of the one corresponding to the input action.
          \item \textbf{conflictsByAlt:} contains couples (event,conflictSet) mapping events to the sets of conflicting events in the agenda.
          \item \textbf{maxPrioByAlt:} contains couples (event, maxPrio) mapping events to the maximum priority in conflictsByAlt(event).
        \end{itemize}
			
			\begin{algorithm}[htp]
              \DontPrintSemicolon
              \SetKwFunction{act}{act}
              \SetKwProg{myalg}{Algorithm}{}{}
              \myalg{\act{actionList}}{
                \If{actionList not empty}{
                	added $\gets$ perform(actionList(0))\;
                	\If{not added}{
                    	alt $\gets$ alternatives(actionList(0))\;
                        conflictsByAlt $\gets$ []\;
                        maxPrioByAlt $\gets$ []\;
                        addedAlt $\gets$ false\;
                        \While{alt not empty AND not addedAlt}{
                        	addedAlt $\gets$ perform(alt(0))\;
                            \If{not addedAlt}{
                            	conflictsByAlt $\gets$ [conflictsByAlt (alt(0),conflicts(alt(0)))]\;
                                maxPrioByAlt $\gets$ [maxPrioByAlt (alt(0),max priority of conflicts(alt(0)))]\;
                                alt.remove(0)\;
                            }
                        }
                        
                        \If{not addedAlt}{
                        	selectedAlt $\gets$ argmin maxPrioByAlt\;
                            movedToAlt $\gets$ true\;
                            \While{conflictsByAlt no empty AND movedToAlt}{
                            	moveActionList $\gets$ list of move actions to the different alternatives of conflict\;
                                movedToAlt $\gets$ act(moveActionList)\;
                            }
                            \uIf{movedToAlt}{
                            	perform(ationList(0))\;
                            }
                            \Else{
                            	\KwRet{false}\;
                            }
                        }
                   	}
                    
                    actionList.remove(0)\;
                    \KwRet{act(actionList)}\;
                }
                \KwRet{true}\;
              }{}
              \caption{Intent Manager algorithm}
              \label{algo:intent}
          	\end{algorithm}
    
    \subsection{NLG and Verbosity Manager}
		
			The NLG module transforms action concepts as well as date, slot, description and yes/no concepts into simple straight forward utterances. For instance the NLG result for the intent ACTION(ADD, EVENT(birthday party, DATE(6,1), SLOT(TIME(21,0),TIME(23,0)))) is \textit{add the event birthday party on January $6^{th}$ from 9pm to 11pm}.
			
			Nevertheless, compared to human/human conversations, limiting interactions to this kind of simple utterances is not realistic. Therefore, they are enhanced in the Verbosity Manager with prefixes like \textit{I would like to}, \textit{Is it possible to}...and suffixes like \textit{if possible}, \textit{please}... In \cite{Ghigi2014}, a corpus study showed that users tend to go off-domain and to repeat the same information several times in the same sentence. These behaviours are also replicated in the Verbosity Manager: 10\% of the times, the US utters an off-domain sentence, and 30\% of the times where there is a misunderstanding, it repeats the same information twice. These proportions have been estimated based on the corpus study mentioned before.
		
    \subsection{ASR output simulator}
    \label{subsec:asroutputsimu}
    
     	The ASR output simulator generates an N-Best that is updated at each new micro-turn. For instance, if at a certain point, the US uttered \textit{I would like to add the event birthday party on...}, a possible N-Best could be (the numbers between brackets represent ASR scores):
        
        \begin{itemize}
					\item (0.82) I would like to add the event birthday party on
					\item (0.65) I like to add the event birthday party on
					\item (0.43) I have had the event birthday party
					\item (0.33) I would like to add the holiday party
					\item (0.31) I like to add the holiday party on
        \end{itemize}
        
       	More formally, at time t, the N-Best is an N-uplet ${(s_1^{(t)},hyp_1^{(t)}),...,(s_N^{(t)},hyp_N^{(t)})}$. At time t+1, a new word $w_{t+1}$ is send to the ASR output simulator and the latter calculates a new associated N-Best. Therefore, at this stage, the system has two N-Best (one for the whole current partial utterance and one for the new word) that it has to combine to obtain the new partial utterance N-Best. In the following how the word N-Best is calculated and how it is incorporated in the partial utterance N-Best.
        
        A Word Error Rate (WER) is given as a parameter to the ASR output simulator. It controls the noise level that one wants to simulate. A Scrambler is used to generate a modified version of some selected words. It can achieve three types of modifications:
        
        \begin{itemize}
        	\item Replace the word with a different word taken randomly from a dictionary (probability: 0.7).
            \item Add a new word (probability : 0.15).
            \item Delete the word (probability : 0.15)
		\end{itemize}
        
        Starting from here, we describe the algorithm used to generate the N-Best associated with a single word.
        
        %HK> Citer le papier d'Olivier et de Richard Beaufort sur la simulation d'ASR en rapport avec ce graph.
        
        \begin{figure}[t]
				\centering
				\begin{tikzpicture}[scale=0.8]
				\begin{axis}[
					xlabel={Score},
					ylabel={Density},
					scaled ticks = false,
					tick label style={/pgf/number format/fixed},
					xmin=0, xmax=1,
					ymin=0, ymax=0.55,
					xtick={0,0.2,0.4,0.6,0.8,1},
					ytick={0.1,0.2,0.3,0.4,0.5,0.6},
                    legend pos=north east,
					ymajorgrids=true,
					grid style=dashed,
                    colorbrewer cycle list=Set2,
				]
				
				\addplot+[
					error bars/.cd,
					y dir=both,
					y explicit,
					]
					coordinates {
					(0,0)
(0.1,0.19483312081792062)
(0.2,0.3702598583755481)
(0.3,0.3943180330023535)
(0.4,0.33431406881442405)
(0.5,0.24197072451914337)
(0.6,0.1485840305841884)
(0.7,0.07242576116369753)
(0.8,0.023141241148471745)
(0.9,0.00240534717059161)
(1,0)
					};
                    
                    \addplot+[
					error bars/.cd,
					y dir=both,
					y explicit,
					]
					coordinates {
					(0,0)
(0.1,0.002405347170591614)
(0.2,0.023141241148471745)
(0.3,0.0724257611636976)
(0.4,0.14858403058418854)
(0.5,0.24197072451914337)
(0.6,0.33431406881442416)
(0.7,0.3943180330023536)
(0.8,0.37025985837554803)
(0.9,0.1948331208179205)
(1,0)

					};
                    

				\legend{Bad recognition,Good recognition}

				\end{axis}
				\end{tikzpicture}
				\caption{ASR score sampling distribution}
				\label{fig:scoresample}
		\end{figure}
    
        \begin{enumerate}
        	\item Determine whether $w_{t+1}$ is among the N-Best or not with a probability that is computed as follows: (1 - WER) + INBF.WER, where INBF (In N-Best Factor) is a parameter between 0 and 1 (set to 0.7 in this thesis). If $w_{t+1}$ is not in the N-Best, then the latter contains only scrambled versions of this word and we directly jump to step 4.
            \item The first hypothesis is set to be $w_{t+1}$ with a probability of (1-WER), otherwise, it is a scrambled version of it.
            \item If the the first hypothesis is not $w_{t+1}$, then this word's position is randomly chosen between 2 and N. Moreover, the other hypothesis are scrambled versions of it.
            \item The confidence score associated to the best hypothesis ($s_0$) is sampled as sigmoid(X) where X is a gaussian. The distribution mean is -1 if the first hypothesis is wrong and 1 when it is right. The standard deviation of X is one. By taking the sigmoid, this leads to two distributions (depicted in Figure \ref{fig:scoresample}) with a mean of 0.3 and 0.7 and a standard deviation of 0.18 for both (which can be changed to simulate different levels of accuracy of the confidence score model. The closest to 0, the better the model).
            \item The scores for the other hypotheses are computed in an iterative way. For $i$ between 2 and N, $s_i$ is uniformly sampled in $[0,s_{i-1}]$.
        \end{enumerate}
        
        In incremental settings, the ASR input is a continuous audio stream. In reality, it is split into small consecutive chunks of data. At each new input arrival, the output is updated. However, a new chunk of audio data in the input does not necessarily translate into a new chunk of text added to the output. In reality, the latter can be partially or even completely changed while update. An example from \cite{Schlangen2011} is when the user utters the word \textit{forty}: the system first understands \textit{four} and then \textit{forty}. The transition between the two hypotheses does not translate into an addition of information but the first hypothesis has to be revoked and replaced by the second one. This phenomenon is referred to as the \textit{ASR instability}.
        
        %HK> Comment justifier l'hypothèse selon laquelle la connaissance NLU peut être utilisée comme un proxy pour le modèle de langage.
        
        To replicate this behaviour, a language model is needed to compute the scores corresponding to the different hypotheses in the N-Best. Therefore, for sentences that are more in alignment with the model will have high scores thus pushed to the top of this N-Best. Here, we use the NLU knowledge as a proxy for the language model by making the following assumption: \textit{the more an utterance generates key concepts once fed to the NLU, the more it is likely to be the correct one}. Therefore, as soon as a new action, date or time slot concept is detected in $hyp_i$, $s_i$ is boosted as follows:
        
        	$$ s_i \leftarrow s_i + BF.(1 - s_i) $$
            
      	where BF is the Boost Factor parameter. Here it is set to 0.2. An illustration of this mechanism is provided in Fig. \ref{fig:asrsimu}.
        
        \begin{figure*}[hb]
          \centering
          \includegraphics[scale=1]{figures/ASRSimu.pdf}
          \caption{An illustration of the incremental ASR output N-Best update}
          \label{fig:asrsimu}
        \end{figure*}
    
    \subsection{Timing and patience manager}
    
    	When it comes to incremental processing, timing is key. However, the main objective of simulation is to generate dialogues in an accelerated mode, hence, no track of timing is kept. In order to approximate durations, the user's and the system's speech rates are considered to be 200 words per minute \cite{Yuan2006}.
        
        Users tend to get impatient, at various degrees, when dialogue systems take too long to accomplish the task they are asked for. To simulate this behaviour, a duration threshold is chosen at each new dialogue task (adding, modifying of deleting an event) that will cause the user to hangup when reached. It is computed as follows
        
       	\begin{eqnarray}
        	d_{pat} = 2 \mu_{pat}.sigmoid(X)
        \end{eqnarray}
        
        where X follows a gaussian distribution of mean 0 and variance 1 and consequently $\mu_{pat}$ is the mean duration threshold.
    