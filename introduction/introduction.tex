\chapter*{Introduction}f

\section*{Context and thesis subject}

				Building machines that are able to vocally communicate with users is driven by the desire to make human-computer interaction as natural\footnote{Naturalness should not be understood as human-likeness. A natural human-machine dialogue consists in an interaction where the machine is able to understand the way humans naturally tend to interact with machines (even though this implies some important variations). However, this may differ from the way they tend to talk to each other. These considerations are thoroughly discussed in \cite{Edlund2008} and summed up in Chapter \ref{ch:stateofart}.} and efficient as possible. Implementing the way humans converse in a machine involves many issues: no more need for traditional interaction devices like the keyboard, hands-free and eye-free interaction (useful in many situations like cars for example), new communication paradigms where a real human-human conversation is simulated...These issues are also emphasised by the new technological trends in the modern world: internet of things, smart devices...Also, recent advances (especially in the field of speech recognition) gave birth to vocal agents both in academia and industry, even though this kind of systems belonged exclusively to the science-fiction domain a few years ago. Nowadays, it is possible to check for restaurants around, check one's account or send a search query on the web by uttering a few words only. Also, conversational agents are able to understand more and more vocabulary and language variations.
				
				Nevertheless, the ability of these systems to engage in a real and natural conversation is still very limited. One of the main reasons is the oversimplified turn-taking mechanism they use: the user and the system take turns in a walkie-talkie fashion since when the user speaks, the system waits until the end of the user's utterance before processing the request, and while the answer is being delivered, the user has no possibility of interrupting the system. This mechanism hurts both the naturalness and the efficiency of the dialogue.
				
				Through several contributions, this thesis addresses the problem of turn-taking capabilities enhancement in dialogue systems. Reinforcement learning is applied to an incremental dialogue system to make it able to optimise turn-taking decisions in an autonomous fashion. First, simple hints and explanations are provided in the following in order to give the reader a first intuition of what reinforcement Learning and incremental dialogue systems mean. The rest of this thesis clarifies these ideas by providing more precise definitions and by grounding the manipulated notions in the current existing literature.

        Originally, a \textbf{dialogue} designates a sequence of communication acts between two or more individuals through natural language, either spoken or written (from Greek, \textit{dia} means \textit{through} and \textit{logos} means \textit{speech}). With the emergence of speech technologies, a research thread (to which this thesis belongs) developed machines that are able to substitute these individuals to a certain extent. They are made of a set of elements that are interacting with each other following precise rules, generally in the purpose of performing a specific task. As a consequence, they are referred to as \textbf{dialogue systems}.

        \textit{Incrementalism} is a method of work aimed to achieve a given task gradually, step by step. The adjective \textbf{incremental} designates any process that advances in that way. At each step, each new laid brick is called an increment. How is that related to dialogue systems? In a nutshell, an utterance is incrementally processed if the listener (the system) does not wait until its end before processing it (understanding it on the fly instead). As a result, these \textbf{incremental dialogue systems} can also utter words or sentences while the speaker is still holding the floor. Inversely, the user can interrupt the incremental expression of the machine and the system will know when it was interrupted.

        In computer science, \textbf{Learning} refers to the field of \textit{Machine Learning} which is the science of building models that will drive algorithms to perform a certain task, and calibrating them automatically from data. \textbf{Reinforcement} is borrowed from the field of behavioral psychology. A behaviour can be strengthened in many ways, like being more frequently performed, for longer durations or after shorter delays for example. This is generally due to a \textit{positive stimulus} received by the agent under study, after adopting this behaviour. \textbf{Reinforcement Learning} is a mathematical framework with algorithms for solving problems through experience.

        So, what is the point of applying reinforcement learning to incremental dialogue systems? What is the problem to solve in such systems? Traditional dialogue systems have only one kind of decision to take: what to say. Incremental dialogue systems, on the other hand, are free to speak whenever they want, which adds an extra dimension to the decisions it should take. In this thesis, decisions about the content of what the system should say are not studied, only timing decisions are focused on. Reinforcement Learning is therefore applied to investigate the following question: can an incremental dialogue system learn the proper timing for speaking by itself?
				
\section*{Motivations}

				According to a study performed by Gartner Consulting, the market of artificial intelligence applications was worth 5 billion dollars in 2014 with an exponential potential growth given the forecasts, reaching a 42 billion dollars size in 2024. As far as personal assistants are concerned, the market size should be multiplied by 13 by then. Therefore, these technologies are on the way of becoming profoundly present in several aspects of our every day life. In order for the vocal modality to be used in such a context, it has to be a robust and comfortable way of human machine interaction in the sense that:
				
				\begin{itemize}
					\item Conversational agents should be reactive enough for the conversation to be smooth and not tedious like it is the case in currently deployed dialogue systems.
					\item Task-oriented dialogue systems should be efficient in such a way that users prefer talking to their devices instead of using any other kind of human/machine interface.
					\item Dialogue strategies should be robust to errors and misunderstandings. They should be able to quickly recover from them in order to avoid desynchronisations between the system and the user.
				\end{itemize}
				
				In traditional dialogue systems, the multiplication of dialogue turns degrades the user experience because of the important silences at each floor transition (from the user to the system and vice-versa). For the same reason, recovering from errors becomes costly which leads to frustrating and tiresome interactions for the user. Moreover, the sooner the error is identified, the lesser there is to unravel. In a world were humans interact more and more with machines several times a day, it is crucial to make the user experience more attractive.
				
				Incremental processing is a powerful tool that enables dialogue systems to fix the current turn-taking limitations. An incremental dialogue system is aimed to process the user's request very quickly as she speaks, which makes it able to provide fast answers and fix errors in a reactive way. The user's and the system's speech are no longer viewed as organised sequences of turns but as a continuous signal where two sources are combined.
				
				Nevertheless, the induced freedom in terms of time sharing between the user and the system can lead to chaotic situations if it is not well managed. Humans use several implicit rules to keep their conversations synchronised, therefore, it is interesting to take a close look towards these mechanism in order to better understand them. The objective of such a study is to make dialogue systems designers aware of the panorama of turn-taking behaviours that they might want to replicate given the task at hand. This can hopefully lead to a first generation of handcrafted turn-taking strategies designed to improve the dialogue efficiency.
				
				Finally, reinforcement learning has been widely used during the last two decades in order to prevent dialogue systems designers to have to set all the parameters. The idea is to set an important part of these parameters directly from data, which objective is twofold: the designers task is simplified and the parameters settings are more accurate since they are estimated from real data. In this thesis, reinforcement learning is not applied to classical dialogue management but it is used to optimise turn-taking decisions. This approach is motivated by the fact that the obtained data-driven strategies have the potential to offer better performances than handcrafted ones.
				
\section*{Objectives and contributions}

				The echosystem in which this thesis took place is the product of the collaboration between academy (LIA) and industry (Orange Labs). As a consequence, the motivations behind this work are twofold:
				
				\begin{itemize}
					\item Bringing theoretical insights which can strengthen our understanding of turn-taking mechanisms in human conversation and help designing new algorithms to enhance incremental dialogue systems turn-taking capabilities.
					\item Building a prototype using industrial tools in order to provide a proof of concept and to demonstrate the advantages of the proposed methodology through real interactions with users.
				\end{itemize}
				
				To do so, the following contributions have been made:
				
				\begin{itemize}
					\item New incremental dialogue architecture \citepublis{Khouzaimi2014a}: it transforms a traditional dialogue system into an incremental one at a low cost. As a proof of concept, it has been implemented in a textual (CFAsT) and a vocal dialogue system (DictaNum, \citepublis{Khouzaimi2014c}).
					\item New turn-taking phenomena taxonomy in human dialogue \citepublis{Khouzaimi2015c}: separating turn-taking behaviours made it possible to make clear choices about which ones should be implemented in an incremental dialogue system in order to improve its efficiency.
					\item New incremental dialogue simulation framework (personal agenda management domain): it is able to simulate incremental ASR instability \citepublis{Khouzaimi2016a}.
					\item Rule-based incremental strategy proposal \citepublis{Khouzaimi2015a}: it has been implemented in simulation and combined with several slot-filling strategies. The results show that the incremental strategy improves dialogue efficiency in terms of dialogue duration and task completion.
					\item Data-driven strategy using reinforcement learning \citepublis{Khouzaimi2015b}: it is implemented in simulation and shown to achieve better results than the rule-based one.
					\item Real users experiment\citepublis{Khouzaimi2016b}: an incremental dialogue system prototype (Majordomo domain) has been developed and used to test the previous strategies with real users.
				\end{itemize}
				
\section*{Outline}

				The first part of this thesis presents the current state of the art in the field of dialogue systems, incremental dialogue systems and turn-taking as well as reinforcement learning and its application to human-machine dialogue. Chapter \ref{ch:stateofart} introduces the generic architecture of a dialogue system and recalls a brief history about each of its components. Incremental dialogue systems are introduced and two different design paradigms are presented. Finally, the basic theoretical background behind reinforcement learning is provided.
				
				Then the second part thoroughly describes the different contributions that have been made during the course of the thesis. Chapter \ref{ch:taxonomy} introduces a new taxonomy of turn-taking phenomena in human conversation. A deep analysis of its different components is made following different study dimensions. Moreover, a discussion is led in order to determine which phenomena are more likely to improve dialogue efficiency if implemented in an incremental dialogue system. Then Chapter \ref{ch:architecture} presents a new architecture for transforming a traditional dialogue system into an incremental one at a low cost as well as two applications that demonstrate its well functioning. This architecture involves a new module called the Scheduler which is in charge of turn-taking decisions. Combining the insights provided in these two chapters, Chapter \ref{ch:strategies} sheds light on how the selected phenomena from the taxonomy could be implemented in the Scheduler in a task-oriented slot-filling task (three slot-filling strategies are also presented).
				
				In order to be able to generate important dialogue corpora, Chapter \ref{ch:simulation} introduces a new framework for incremental dialogue simulation which is able to simulate incremental ASR instability. A User Simulator communicates with an incremental dialogue system (composed of a Service for personal agenda management and a Scheduler) through an ASR Output Simulator. The strategies discussed in Chapter \ref{ch:baseline} are implemented in this simulated environment and compared. Chapter \ref{ch:rl} introduces a new strategy that is learned automatically from simulated dialogues using reinforcement learning. The results are compared to the ones offered by handcrafed strategies and presented in Chapter \ref{ch:baseline}.
				
				Finally, Chapter \ref{ch:experiment} describes an experiment with real users where interactions take place with a Majordomo agent: the users act as if they are interacting with their smart home. A non-incremental strategy as well as a handcrafted incremental and a data-driven one are compared in order to validate the results obtained by simulation.

\bibliographystylepublis{lia-these-fr}
\bibliographypublis{biblio}
